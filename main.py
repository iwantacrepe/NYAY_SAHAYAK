import streamlit as st
import google.generativeai as genai
import os
import json
from dotenv import load_dotenv
from PyPDF2 import PdfReader
import docx
from PIL import Image
import time

# --- Configuration and Setup ---

# Load environment variables
load_dotenv()

# Configure Streamlit page
st.set_page_config(
    page_title="Nyay Sahayak",
    page_icon="‚öñÔ∏è",
    layout="wide"
)

# Configure the Generative AI model
try:
    genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
except Exception as e:
    st.error(f"API Configuration Error: Please ensure your GOOGLE_API_KEY is set in .env. Details: {e}")

# --- UI Internationalization (i18n) Dictionary (Unchanged) ---
translations = {
    "en": {
        "page_title": "Nyay Sahayak: Kanooni Madad, Aapke Sath",
        "sidebar_header": "Settings",
        "language_select": "Select Output Language",
        "disclaimer": "This is a prototype created for the Gen AI Exchange Hackathon. It is not a substitute for professional legal advice.",
        "uploader_label": "Upload your legal document (PDF, DOCX, PNG, JPG)",
        "button_text": "Begin Multi-Agent Analysis",
        "analysis_complete_header": "Analysis Complete",
        "tab_overview": "üìä At-a-Glance Dashboard",
        "tab_breakdown": "üìñ Detailed Breakdown",
        "tab_strategic": "üí° Strategic Insights",
        "tab_cases": "üèõÔ∏è Related Cases",
        "overview_summary": "Quick Summary",
        "overview_doc_type": "Document Type",
        "overview_strength": "Case Strength (Lower is Better)",
        "overview_assessment": "Case Strength Assessment",
        "overview_reasoning": "Reasoning",
        "overview_parties": "Parties Involved",
        "overview_takeaways": "Key Takeaways for You",
        "breakdown_header": "Detailed Document Understanding",
        "breakdown_comp_summary_header": "Comprehensive Summary",
        "strategic_header_points": "Key Points for Hearing/Negotiation",
        "strategic_header_sections": "Legal Sections & Acts Mentioned",
        "cases_header": "Related Case Law & Precedents",
        "cases_disclaimer": "üö® DISCLAIMER: This is AI-generated information for educational purposes ONLY and is not legal advice. Consult a qualified lawyer.",
        "qna_header": "üí¨ Ask Follow-up Questions",
        "qna_input_placeholder": "Ask a specific question about the document...",
        "lang_change_popup_text": "You have changed the language. To view the analysis in the new language, please re-run the process.",
        "rerun_button": "Translate Results",
        "point_label": "Point",
        "importance_label": "Importance",
        "case_label": "Case",
        "precedent_label": "Precedent",
        "progress_text": "Analyzing your document... Please wait."
    },
    "hi": {
        "page_title": "‡§®‡•ç‡§Ø‡§æ‡§Ø ‡§∏‡§π‡§æ‡§Ø‡§ï: ‡§ï‡§æ‡§®‡•Ç‡§®‡•Ä ‡§Æ‡§¶‡§¶, ‡§Ü‡§™‡§ï‡•á ‡§∏‡§æ‡§•",
        "sidebar_header": "‡§∏‡•á‡§ü‡§ø‡§Ç‡§ó‡•ç‡§∏",
        "language_select": "‡§Ü‡§â‡§ü‡§™‡•Å‡§ü ‡§≠‡§æ‡§∑‡§æ ‡§ö‡•Å‡§®‡•á‡§Ç",
        "disclaimer": "‡§Ø‡§π ‡§ú‡•á‡§® ‡§è‡§Ü‡§à ‡§è‡§ï‡•ç‡§∏‡§ö‡•á‡§Ç‡§ú ‡§π‡•à‡§ï‡§•‡•â‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§¨‡§®‡§æ‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§è‡§ï ‡§™‡•ç‡§∞‡•ã‡§ü‡•ã‡§ü‡§æ‡§á‡§™ ‡§π‡•à‡•§ ‡§Ø‡§π ‡§™‡•á‡§∂‡•á‡§µ‡§∞ ‡§ï‡§æ‡§®‡•Ç‡§®‡•Ä ‡§∏‡§≤‡§æ‡§π ‡§ï‡§æ ‡§µ‡§ø‡§ï‡§≤‡•ç‡§™ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à‡•§",
        "uploader_label": "‡§Ö‡§™‡§®‡§æ ‡§ï‡§æ‡§®‡•Ç‡§®‡•Ä ‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç (PDF, DOCX, PNG, JPG)",
        "button_text": "‡§Æ‡§≤‡•ç‡§ü‡•Ä-‡§è‡§ú‡•á‡§Ç‡§ü ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§∂‡•Å‡§∞‡•Ç ‡§ï‡§∞‡•á‡§Ç",
        "analysis_complete_header": "‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§™‡•Ç‡§∞‡§æ ‡§π‡•Å‡§Ü",
        "tab_overview": "üìä ‡§è‡§ï ‡§®‡§ú‡§º‡§∞ ‡§Æ‡•á‡§Ç ‡§°‡•à‡§∂‡§¨‡•ã‡§∞‡•ç‡§°",
        "tab_breakdown": "üìñ ‡§µ‡§ø‡§∏‡•ç‡§§‡•É‡§§ ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£",
        "tab_strategic": "üí° ‡§∞‡§£‡§®‡•Ä‡§§‡§ø‡§ï ‡§Ö‡§Ç‡§§‡§∞‡•ç‡§¶‡•É‡§∑‡•ç‡§ü‡§ø",
        "tab_cases": "üèõÔ∏è ‡§∏‡§Ç‡§¨‡§Ç‡§ß‡§ø‡§§ ‡§Æ‡§æ‡§Æ‡§≤‡•á",
        "overview_summary": "‡§∏‡§Ç‡§ï‡•ç‡§∑‡§ø‡§™‡•ç‡§§ ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂",
        "overview_doc_type": "‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º ‡§ï‡§æ ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞",
        "overview_strength": "‡§ï‡•á‡§∏ ‡§ï‡•Ä ‡§§‡§æ‡§ï‡§§ (‡§ï‡§Æ ‡§¨‡•á‡§π‡§§‡§∞ ‡§π‡•à)",
        "overview_assessment": "‡§ï‡•á‡§∏ ‡§ï‡•Ä ‡§§‡§æ‡§ï‡§§ ‡§ï‡§æ ‡§Ü‡§ï‡§≤‡§®",
        "overview_reasoning": "‡§§‡§∞‡•ç‡§ï",
        "overview_parties": "‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§™‡§ï‡•ç‡§∑",
        "overview_takeaways": "‡§Ü‡§™‡§ï‡•á ‡§≤‡§ø‡§è ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§¨‡§æ‡§§‡•á‡§Ç",
        "breakdown_header": "‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º ‡§ï‡•Ä ‡§µ‡§ø‡§∏‡•ç‡§§‡•É‡§§ ‡§∏‡§Æ‡§ù",
        "breakdown_comp_summary_header": "‡§µ‡§ø‡§∏‡•ç‡§§‡•É‡§§ ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂",
        "strategic_header_points": "‡§∏‡•Å‡§®‡§µ‡§æ‡§à/‡§¨‡§æ‡§§‡§ö‡•Ä‡§§ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§¨‡§ø‡§Ç‡§¶‡•Å",
        "strategic_header_sections": "‡§â‡§≤‡•ç‡§≤‡§ø‡§ñ‡§ø‡§§ ‡§ï‡§æ‡§®‡•Ç‡§®‡•Ä ‡§ß‡§æ‡§∞‡§æ‡§è‡§Ç ‡§î‡§∞ ‡§Ö‡§ß‡§ø‡§®‡§ø‡§Ø‡§Æ",
        "cases_header": "‡§∏‡§Ç‡§¨‡§Ç‡§ß‡§ø‡§§ ‡§Æ‡§æ‡§Æ‡§≤‡•á ‡§î‡§∞ ‡§Æ‡§ø‡§∏‡§æ‡§≤‡•á‡§Ç",
        "cases_disclaimer": "üö® ‡§Ö‡§∏‡•ç‡§µ‡•Ä‡§ï‡§∞‡§£: ‡§Ø‡§π ‡§ï‡•á‡§µ‡§≤ ‡§∂‡•à‡§ï‡•ç‡§∑‡§ø‡§ï ‡§â‡§¶‡•ç‡§¶‡•á‡§∂‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§Ü‡§à-‡§ú‡§®‡§ø‡§§ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§π‡•à ‡§î‡§∞ ‡§ï‡§æ‡§®‡•Ç‡§®‡•Ä ‡§∏‡§≤‡§æ‡§π ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à‡•§ ‡§è‡§ï ‡§Ø‡•ã‡§ó‡•ç‡§Ø ‡§µ‡§ï‡•Ä‡§≤ ‡§∏‡•á ‡§™‡§∞‡§æ‡§Æ‡§∞‡•ç‡§∂ ‡§ï‡§∞‡•á‡§Ç‡•§",
        "qna_header": "üí¨ ‡§Ö‡§®‡•Å‡§µ‡§∞‡•ç‡§§‡•Ä ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§™‡•Ç‡§õ‡•á‡§Ç",
        "qna_input_placeholder": "‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§™‡•Ç‡§õ‡•á‡§Ç...",
        "lang_change_popup_text": "‡§Ü‡§™‡§®‡•á ‡§≠‡§æ‡§∑‡§æ ‡§¨‡§¶‡§≤ ‡§¶‡•Ä ‡§π‡•à‡•§ ‡§®‡§è ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•á‡§Ç ‡§™‡§∞‡§ø‡§£‡§æ‡§Æ ‡§¶‡•á‡§ñ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è, ‡§ï‡•É‡§™‡§Ø‡§æ ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§´‡§ø‡§∞ ‡§∏‡•á ‡§ö‡§≤‡§æ‡§è‡§Ç‡•§",
        "rerun_button": "‡§™‡§∞‡§ø‡§£‡§æ‡§Æ‡•ã‡§Ç ‡§ï‡§æ ‡§Ö‡§®‡•Å‡§µ‡§æ‡§¶ ‡§ï‡§∞‡•á‡§Ç",
        "point_label": "‡§¨‡§ø‡§Ç‡§¶‡•Å",
        "importance_label": "‡§Æ‡§π‡§§‡•ç‡§µ",
        "case_label": "‡§Æ‡§æ‡§Æ‡§≤‡§æ",
        "precedent_label": "‡§Æ‡§ø‡§∏‡§æ‡§≤",
        "progress_text": "‡§Ü‡§™‡§ï‡•á ‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º ‡§ï‡§æ ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ ‡§∞‡§π‡§æ ‡§π‡•à... ‡§ï‡•É‡§™‡§Ø‡§æ ‡§™‡•ç‡§∞‡§§‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§ï‡§∞‡•á‡§Ç‡•§"
    }
}

# --- Multi-Format Input Handling (Unchanged) ---
def get_document_content(uploaded_files):
    text = ""
    for uploaded_file in uploaded_files:
        file_extension = os.path.splitext(uploaded_file.name)[1].lower()
        if file_extension == ".pdf":
            try:
                pdf_reader = PdfReader(uploaded_file);
                for page in pdf_reader.pages: text += page.extract_text()
            except Exception as e: st.error(f"Error reading PDF file: {e}"); return None
        elif file_extension == ".docx":
            try:
                doc = docx.Document(uploaded_file);
                for para in doc.paragraphs: text += para.text + "\n"
            except Exception as e: st.error(f"Error reading DOCX file: {e}"); return None
        elif file_extension in [".png", ".jpg", ".jpeg"]:
            try:
                image = Image.open(uploaded_file);
                vision_model = genai.GenerativeModel("gemini-1.5-flash");
                response = vision_model.generate_content(["Extract all text from this image of a legal document.", image]);
                text += response.text + "\n"
            except Exception as e: st.error(f"Error processing image file: {e}"); return None
    return text

# --- Core AI Functions (Unchanged) ---
def get_gemini_response(prompt, model_name="gemini-1.5-flash"):
    try:
        model = genai.GenerativeModel(model_name)
        response = model.generate_content(prompt)
        if not hasattr(response, 'text'):
            st.error(f"The model returned an empty response. This may be due to safety settings or an internal error.")
            return None
        clean_json_str = response.text.strip().replace("```json", "").replace("```", "")
        return json.loads(clean_json_str)
    except json.JSONDecodeError:
        st.error("The AI's response was not in the expected JSON format. Please try again.")
        st.text_area("Raw AI Response for debugging:", response.text if 'response' in locals() else "No response received.")
        return None
    except Exception as e:
        st.error(f"An API error occurred with model {model_name}: {e}")
        return None

# --- THE MULTI-AGENT SYSTEM (with FINAL prompts for simple language and depth) ---

# This helper string will be used in all agents to ensure simple Hindi
HINDI_INSTRUCTION = """
**If the target language is Hindi, you MUST follow this critical instruction:**
Your user is an average person, not a legal expert. Do NOT use difficult or pure 'shuddh' Hindi words.
Use simple, conversational, everyday Hindi (often called Hinglish).
For example:
- Instead of '‡§®‡•ç‡§Ø‡§æ‡§Ø‡§æ‡§≤‡§Ø', use '‡§ï‡•ã‡§∞‡•ç‡§ü'.
- Instead of '‡§Ö‡§ß‡§ø‡§µ‡§ï‡•ç‡§§‡§æ', use '‡§µ‡§ï‡•Ä‡§≤'.
- Instead of '‡§Ø‡§æ‡§ö‡§ø‡§ï‡§æ‡§ï‡§∞‡•ç‡§§‡§æ', use '‡§Ö‡§∞‡•ç‡§ú‡•Ä ‡§¶‡•á‡§®‡•á ‡§µ‡§æ‡§≤‡§æ' or '‡§Ø‡§æ‡§ö‡§ø‡§ï‡§æ‡§ï‡§∞‡•ç‡§§‡§æ'.
- Instead of '‡§™‡•ç‡§∞‡§§‡§ø‡§µ‡§æ‡§¶‡•Ä', use '‡§ú‡§ø‡§∏‡§ï‡•á ‡§ñ‡§ø‡§≤‡§æ‡§´ ‡§ï‡•á‡§∏ ‡§π‡•à' or '‡§™‡•ç‡§∞‡§§‡§ø‡§µ‡§æ‡§¶‡•Ä'.
The goal is MAXIMUM simplicity and readability for a common person.
"""

def run_triage_agent(document_text, language="English"):
    json_structure_string = f"""{{ "document_type": "...", "parties_involved": [{{ "role": "Translate this role (e.g., 'Applicant', 'Respondent') to {language}.", "name": "..."}}], "legal_sections_mentioned": ["..."] }}"""
    prompt = f"""You are a Triage Agent. Your task is to perform a quick scan of the legal document below and extract key metadata.
    {HINDI_INSTRUCTION if language == "Hindi" else ""}
    Translate all string values in the final JSON to {language}. Output a single, valid JSON object.
    Document Text: --- {document_text[:4000]} ---
    JSON Structure: {json_structure_string}
    """
    return get_gemini_response(prompt)

def run_demystifier_agent(document_text, language="English"):
    prompt = f"""
    You are a Demystifier Agent. Your task is to provide a very detailed, simple-language breakdown of the legal document.
    {HINDI_INSTRUCTION if language == "Hindi" else ""}
    Translate all string values in the final JSON to {language}. Output a single, valid JSON object.

    Document Text: --- {document_text} ---
    JSON Structure: {{
        "quick_summary": "Provide a clear, simple, 4-5 line summary of what this paper is about and what it wants to achieve.",
        "comprehensive_summary": "Provide a very detailed, multi-paragraph summary covering all key aspects of the document. This should be exhaustive (at least 300 words). Structure it logically: 1. Start with the background of the case. 2. Detail the main arguments presented by the applicant. 3. List the key evidence or points mentioned to support the arguments. 4. State the final request or 'prayer' made to the court. Ensure all points from the original document are covered in this detailed summary.",
        "key_takeaways_for_user": ["List 3-4 of the most important, action-oriented points for the user. Make each point a detailed, multi-sentence explanation of what the user needs to know or do."],
        "detailed_understanding": [{{ "heading": "Provide a clear heading for a major section in simple language.", "explanation": "Explain this section in extremely simple, practical, and very detailed terms, using at least two paragraphs. Use analogies if helpful."}}]
    }}
    """
    return get_gemini_response(prompt)

def run_strategic_advisor_agent(document_text, language="English"):
    prompt = f"""
    You are a Strategic Advisor Agent. Based on the document, provide a detailed strategic assessment and actionable points in simple language.
    {HINDI_INSTRUCTION if language == "Hindi" else ""}
    Translate all string values in the final JSON to {language}. Output a single, valid JSON object.
    Document Text: --- {document_text} ---
    JSON Structure: {{
        "case_strength_assessment": {{ "score": "On a scale of 1-10 (1=very strong, 10=very weak), assess the strength of the case for the primary applicant.", "reasoning": "Provide a detailed, multi-sentence reasoning for your score, elaborating on the strengths and weaknesses." }},
        "key_points_for_hearing": [ {{ "point": "Identify a critical point or argument.", "importance": "Explain in detail (at least two sentences) why this point is so important and how it can be argued effectively." }} ]
    }}
    """
    return get_gemini_response(prompt)

def run_legal_scholar_agent(triage_data, language="English"):
    sections = ", ".join(triage_data.get("legal_sections_mentioned", []))
    doc_type = triage_data.get("document_type", "legal document")
    if not sections: return {"related_cases": [{"case_name": "No specific legal sections found to research.", "precedent_summary": "Please ensure the document clearly states the laws or sections it is based on."}]}
    prompt = f"""
    You are a Legal Scholar Agent. Based on an {doc_type} involving sections {sections}, find relevant landmark case laws from India.
    {HINDI_INSTRUCTION if language == "Hindi" else ""}
    Translate all string values in the final JSON to {language}. Output a single, valid JSON object.
    JSON Structure: {{ "related_cases": [{{ "case_name": "Full case name", "precedent_summary": "Explain the case's main outcome, its context, and its importance in simple, detailed, multi-sentence terms." }}] }}
    """
    return get_gemini_response(prompt)

# --- THE ORCHESTRATOR (Unchanged) ---
def run_orchestrator(document_text, language, lang_code, progress_placeholder, progress_text_key):
    st.session_state.analysis_data = {}
    progress_bar = progress_placeholder.progress(0, text=translations.get(lang_code, translations['en'])[progress_text_key])
    agents = [
        {"func": run_triage_agent, "name": "triage"},
        {"func": run_demystifier_agent, "name": "demystifier"},
        {"func": run_strategic_advisor_agent, "name": "advisor"}
    ]
    total_agents = len(agents) + 1
    for i, agent in enumerate(agents):
        results = agent["func"](document_text, language)
        progress = int(((i + 1) / total_agents) * 100)
        progress_bar.progress(progress, text=translations.get(lang_code, translations['en'])[progress_text_key])
        if not results:
            st.error(f"{agent['name'].capitalize()} Agent failed. Analysis stopped.")
            progress_placeholder.empty()
            return
        st.session_state.analysis_data[agent['name']] = results
    scholar_results = run_legal_scholar_agent(st.session_state.analysis_data['triage'], language)
    progress_bar.progress(100, text=translations.get(lang_code, translations['en'])[progress_text_key])
    if not scholar_results:
        st.error("Legal Scholar Agent failed.")
        progress_placeholder.empty()
        return
    st.session_state.analysis_data['scholar'] = scholar_results
    time.sleep(1)
    progress_placeholder.empty()
    st.session_state.analysis_done = True
    st.session_state.document_context = document_text
    st.session_state.analysis_language = lang_code

# --- STREAMLIT UI (Unchanged) ---
if "analysis_done" not in st.session_state: st.session_state.analysis_done = False
if "analysis_language" not in st.session_state: st.session_state.analysis_language = "en"
if "document_context" not in st.session_state: st.session_state.document_context = ""

lang_map = {"English": "en", "‡§π‡§ø‡§Ç‡§¶‡•Ä (Hindi)": "hi"}
selected_lang_name = st.sidebar.selectbox("Select Language / ‡§≠‡§æ‡§∑‡§æ ‡§ö‡•Å‡§®‡•á‡§Ç", list(lang_map.keys()), key="language_selector")
lang_code = lang_map[selected_lang_name]
T = translations.get(lang_code, translations['en'])

st.title(T["page_title"])
with st.sidebar:
    st.image("https://tse4.mm.bing.net/th/id/OIP.pKYxAsdzwLdveNPRvfdFQwHaEK?rs=1&pid=ImgDetMain&o=7&rm=3",width=250)
    st.header(T["sidebar_header"])
    st.info(T["disclaimer"])

if st.session_state.analysis_done and st.session_state.analysis_language != lang_code:
    with st.container(border=True):
        st.info(T["lang_change_popup_text"])
        if st.button(T["rerun_button"], key="rerun_translation"):
            progress_placeholder = st.empty()
            run_orchestrator(st.session_state.document_context, selected_lang_name.split(" ")[0], lang_code, progress_placeholder, "progress_text")
            st.rerun()

uploaded_files = st.file_uploader(T["uploader_label"], type=["pdf", "docx", "png", "jpg", "jpeg"], accept_multiple_files=True, key="file_uploader")
progress_placeholder = st.empty()

if st.button(T["button_text"], disabled=not uploaded_files):
    st.session_state.analysis_done = False
    content = get_document_content(uploaded_files)
    if content:
        run_orchestrator(content, selected_lang_name.split(" ")[0], lang_code, progress_placeholder, "progress_text")
        st.rerun()

if st.session_state.analysis_done:
    data = st.session_state.analysis_data
    triage, demystifier, advisor, scholar = data.get('triage', {}), data.get('demystifier', {}), data.get('advisor', {}), data.get('scholar', {})
    st.header(T["analysis_complete_header"], divider='rainbow')
    tab1, tab2, tab3, tab4 = st.tabs([T["tab_overview"], T["tab_breakdown"], T["tab_strategic"], T["tab_cases"]])
    with tab1:
        st.subheader(T["overview_summary"]); st.write(demystifier.get('quick_summary'))
        st.subheader(T["overview_takeaways"]); 
        for takeaway in demystifier.get('key_takeaways_for_user', []): st.success(f"üëâ {takeaway}")
        st.divider()
        col1, col2 = st.columns(2)
        with col1:
            st.subheader(T["overview_doc_type"]); st.info(triage.get('document_type'))
            st.subheader(T["overview_parties"]); 
            for party in triage.get('parties_involved', []): st.markdown(f"- **{party.get('role')}:** {party.get('name')}")
        with col2:
            st.subheader(T["overview_assessment"])
            assessment = advisor.get('case_strength_assessment', {})
            st.metric(T["overview_strength"], f"{assessment.get('score')}/10")
            st.warning(f"**{T['overview_reasoning']}:** {assessment.get('reasoning')}")
    with tab2:
        st.subheader(T["breakdown_comp_summary_header"]); st.write(demystifier.get('comprehensive_summary'))
        st.divider()
        st.subheader(T["breakdown_header"]); 
        for item in demystifier.get('detailed_understanding', []):
            with st.expander(f"**{item.get('heading')}**"): st.write(item.get('explanation'))
    with tab3:
        st.subheader(T["strategic_header_points"])
        for item in advisor.get('key_points_for_hearing', []):
            if isinstance(item, dict):
                container = st.container(border=True)
                container.markdown(f"**{T['point_label']}:** {item.get('point')}")
                container.info(f"**{T['importance_label']}:** {item.get('importance')}")
        st.subheader(T["strategic_header_sections"]); st.code(", ".join(triage.get('legal_sections_mentioned', ['None'])))
    with tab4:
        st.subheader(T["cases_header"]); st.error(T["cases_disclaimer"])
        for case in scholar.get('related_cases', []):
            container = st.container(border=True)
            container.markdown(f"**{T['case_label']}:** {case.get('case_name')}")
            container.info(f"**{T['precedent_label']}:** {case.get('precedent_summary')}")
    st.header(T["qna_header"], divider='rainbow')
    if "messages" not in st.session_state: st.session_state.messages = []
    for message in st.session_state.messages:
        with st.chat_message(message["role"]): st.markdown(message["content"])
    if prompt := st.chat_input(T["qna_input_placeholder"]):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"): st.markdown(prompt)
        with st.chat_message("assistant"):
            with st.spinner("Thinking..."):
                qna_prompt = f"Context:\n{st.session_state.document_context}\n\nQuestion: {prompt}\n\nAnswer the question based ONLY on the context. {HINDI_INSTRUCTION if language == 'Hindi' else 'Use extremely simple language.'}"
                model = genai.GenerativeModel('gemini-1.5-pro')
                response = model.generate_content(qna_prompt)
                st.markdown(response.text)
                st.session_state.messages.append({"role": "assistant", "content": response.text})